{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import math\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deployment = \"https://vip.domino.tech\"\n",
    "model_version_id = \"5bb6a0d3c9e77c0007cdd20a\"\n",
    "log_file = \"churn-model-api-logs.txt\"\n",
    "output_file = log_file + \".gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timestamp_ms(year, month, day, hour, minute):\n",
    "    dt = datetime(year=year, month=month, day=day, hour=hour, minute=minute, tzinfo=timezone(\"US/Pacific\"))\n",
    "    ts_ms = math.floor(dt.timestamp())*1000\n",
    "    print(ts_ms)\n",
    "    return(ts_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOW = True\n",
    "ZEROSTART = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (NOW):\n",
    "    endMillis = math.floor(datetime.now(timezone(\"US/Pacific\")).timestamp())*1000\n",
    "else:\n",
    "    endMillis = get_timestamp_ms(2018, 10, 4, 16, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (ZEROSTART):\n",
    "    startMillis = 0\n",
    "else:\n",
    "    startMillis = get_timestamp_ms(2018, 10, 5, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CURL String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_logs = \"curl --header \\\"accept: application/x-ndjson\\\" --header \\\"X-Domino-Api-Key: \" \\\n",
    "            + os.environ['DOMINO_USER_API_KEY'] \\\n",
    "            + \"\\\" '\" + deployment \\\n",
    "            + \"/v4/modelManager/\" + model_version_id \\\n",
    "            + \"/logs?startMillis=\" + str(startMillis) \\\n",
    "            + \"&endMillis=\" + str(endMillis) + \"'\" \\\n",
    "            + \" --output \" + output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  6358    0  6358    0     0    279      0 --:--:--  0:00:22 --:--:--  1849\n"
     ]
    }
   ],
   "source": [
    "! rm $log_file\n",
    "! $get_logs\n",
    "! gunzip $output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Historical File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_file = \"/mnt/data/churn_model_logs.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timeStamp\": \"20181009T140008.769Z\", \"requestId\": \"1O3RFIANSBWLTXV9\", \"input\": {\"data\": {\"dropperc\": 0.006245420561149054, \"mins\": 411.38621878639617, \"consecmonths\": 32.038837314038155, \"income\": 96.40603776531253}}, \"httpResponse\": 200, \"output\": [0.0014309354810836232], \"timingMillis\": 1}\n",
      "{\"timeStamp\": \"20181009T184456.099Z\", \"requestId\": \"JX5MTLOB3G8YAU0F\", \"input\": {\"data\": {\"dropperc\": 0.03, \"mins\": 400, \"consecmonths\": 23, \"income\": 20}}, \"httpResponse\": 200, \"output\": [6.071834820021662e-05], \"timingMillis\": 0}\n"
     ]
    }
   ],
   "source": [
    "# view raw text\n",
    "\n",
    "f = open(log_file, \"r\")\n",
    "data = f.read()\n",
    "i=1\n",
    "printlist = data.split(\"\\n\")\n",
    "for line in printlist:\n",
    "    if i <= 2: print(line)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse with json library\n",
    "# view first line\n",
    "\n",
    "import json\n",
    "# one line at a time in a list\n",
    "data = []\n",
    "for line in open(log_file, 'r'):\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load into df\n",
    "# view first rows\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 'input'\n",
    "# view first rows\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "input_df = json_normalize(df.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten 'output'\n",
    "# not formatted right for json_normalized\n",
    "# use string functions\n",
    "# view pre and post processing\n",
    "\n",
    "s=\"\"\n",
    "for v in df.output.values:\n",
    "     s+=str(v) + \",\"\n",
    "res=[s]\n",
    "res[0] = res[0][:-1]\n",
    "res[0] = res[0].replace(\"{'churn_Y': \",\"\")\n",
    "res[0] = res[0].replace(\"}\",\"\")\n",
    "res[0] = res[0].replace(\"nan\",\"\")\n",
    "res[0] = res[0].replace(\"[\",\"\")\n",
    "res[0] = res[0].replace(\"]\",\"\")\n",
    "out_list = res[0].split(\",\")\n",
    "out_df = pd.DataFrame({'output':out_list})\n",
    "out_df = out_df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join input and output back in\n",
    "# view first rows\n",
    "\n",
    "df = df.drop(['input'],axis=1)\n",
    "df = df.drop(['output'],axis=1)\n",
    "collist = df.columns.values.tolist()\n",
    "df = df[collist].join(input_df).join(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Historical File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab historical data\n",
    "\n",
    "import json\n",
    "# one line at a time in a list\n",
    "data_baseline = []\n",
    "for line in open(historical_file, 'r'):\n",
    "    data_baseline.append(json.loads(line))\n",
    "    \n",
    "import pandas as pd\n",
    "df_baseline = pd.read_json(json.dumps(data_baseline))\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "input_df_baseline = json_normalize(df_baseline.input)\n",
    "\n",
    "s=\"\"\n",
    "for v in df_baseline.output.values:\n",
    "     s+=str(v) + \",\"\n",
    "res=[s]\n",
    "res[0] = res[0][:-1]\n",
    "res[0] = res[0].replace(\"{'churn_Y': \",\"\")\n",
    "res[0] = res[0].replace(\"}\",\"\")\n",
    "res[0] = res[0].replace(\"nan\",\"\")\n",
    "res[0] = res[0].replace(\"[\",\"\")\n",
    "res[0] = res[0].replace(\"]\",\"\")\n",
    "out_list_baseline = res[0].split(\",\")\n",
    "out_df_baseline = pd.DataFrame({'output':out_list_baseline})\n",
    "out_df_baseline = out_df_baseline.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "df_baseline = df_baseline.drop(['input'],axis=1)\n",
    "df_baseline = df_baseline.drop(['output'],axis=1)\n",
    "collist = df_baseline.columns.values.tolist()\n",
    "df_baseline = df_baseline[collist].join(input_df_baseline).join(out_df_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Log and Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries for graphing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['timeStamp'])\n",
    "df_baseline = df_baseline.sort_values(by=['timeStamp'])\n",
    "df.to_csv('/mnt/data/parsed_model_log.csv')\n",
    "df_baseline.to_csv('/mnt/data/parsed_model_log_baseline.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
